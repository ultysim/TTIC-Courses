{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import edf\n",
    "from time import time\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.load('./c10_data/train.npz')\n",
    "t_imgs = np.float32(data['imgs'])/255.\n",
    "\n",
    "# Reshape the train image data to (idx, h, w, channel)\n",
    "t_imgs = t_imgs.reshape(50000, 32, 32, 3)\n",
    "t_labels = np.float32(data['labels'])\n",
    "\n",
    "data = np.load('./c10_data/test.npz')\n",
    "v_imgs = np.float32(data['imgs'])/255.\n",
    "\n",
    "# Reshape the valid image data to (idx, h, w, channel)\n",
    "v_imgs = v_imgs.reshape(10000, 32, 32, 3)\n",
    "v_labels = np.float32(data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "########################################### Convolution layer#############################################\n",
    "############################### Please implement the forward abd backward method in this class ############## \n",
    "class Conv:\n",
    "\n",
    "    def __init__(self,x,f,stride=1,pad=0):\n",
    "        edf.components.append(self)\n",
    "        self.f = f\n",
    "        self.x = x\n",
    "        pad = np.array(pad)\n",
    "        if pad.shape == ():\n",
    "            self.xpad = self.ypad = pad\n",
    "        else:\n",
    "            self.ypad = pad[0]\n",
    "            self.xpad = pad[1]\n",
    "            \n",
    "        self.stride=stride\n",
    "        self.grad = None if f.grad is None and x.grad is None else edf.DT(0) \n",
    "\n",
    "    ####################### Please implement this function####################### \n",
    "    def forward(self):\n",
    "        x = self.x.value\n",
    "        f = self.f.value\n",
    "        datapad = np.zeros((x.shape[0],x.shape[1]+2*self.ypad,x.shape[2]+2*self.xpad,x.shape[3]))\n",
    "        datapad[:,self.ypad:self.ypad+x.shape[1],self.xpad:self.xpad+x.shape[2],:] = x\n",
    "        self.value = np.zeros((x.shape[0],(x.shape[1]+2*self.ypad-f.shape[0])/self.stride+1,(x.shape[2]+2*self.xpad-f.shape[0])/self.stride +1,f.shape[3]))\n",
    "        s = self.stride\n",
    "        k = f.shape[0]\n",
    "        self.datapad = datapad\n",
    "        for i in range(self.value.shape[1]):\n",
    "            for j in range(self.value.shape[2]):\n",
    "                self.value[:,i,j,:] = np.tensordot(datapad[:,s*i:s*i+k,s*j:s*j+k,:],f,axes=[[1,2,3],[0,1,2]])\n",
    "  \n",
    "\n",
    "                \n",
    "    ####################### Please implement this function#######################         \n",
    "    def backward(self):\n",
    "        s = self.stride\n",
    "        k = self.f.value.shape[0]\n",
    "        if self.x.grad is None or len(self.x.grad.shape) < 3:\n",
    "            self.x.grad = np.ndarray((self.x.value.shape))\n",
    "        #Pad the x.grad:\n",
    "        gradpad = np.zeros((self.x.grad.shape[0],self.x.grad.shape[1]+2*self.ypad,self.x.grad.shape[2]+2*self.xpad,self.x.grad.shape[3]))\n",
    "        gradpad[:,self.ypad:self.ypad+self.x.grad.shape[1],self.xpad:self.xpad+self.x.grad.shape[2],:] = self.x.grad\n",
    "        for i in range(self.value.shape[1]):\n",
    "            for j in range(self.value.shape[2]):\n",
    "\n",
    "                gradpad[:,s*i:s*i+k,s*j:s*j+k,:] += np.tensordot(self.grad[:,i,j,:],self.f.value,axes=(1,3))\n",
    "                self.f.grad += np.tensordot(self.datapad[:,s*i:s*i+k,s*j:s*j+k,:],self.grad[:,i,j,:],axes=(0,0))\n",
    "                \n",
    "        self.x.grad = gradpad[:,self.ypad:self.ypad+self.x.value.shape[1],self.xpad:self.xpad+self.x.value.shape[2],:]\n",
    "\n",
    "\n",
    "\n",
    "########################################### MaxPool layer#############################################\n",
    "############################### Please implement the forward abd backward method in this class ##############             \n",
    "class MaxPool:\n",
    "    def __init__(self,x,ksz=2,stride=None):\n",
    "        edf.components.append(self)\n",
    "        self.x = x\n",
    "        self.ksz=ksz\n",
    "        if stride is None:\n",
    "            self.stride=ksz\n",
    "        else:\n",
    "            self.stride=stride\n",
    "        self.grad = None if x.grad is None else edf.DT(0)\n",
    "\n",
    "    ####################### Please implement this function#######################     \n",
    "    def forward(self):\n",
    "        x = self.x.value\n",
    "        hold = x.reshape((x.shape[0],x.shape[1]/self.stride,self.stride,x.shape[2]/self.stride,self.stride,x.shape[3]))\n",
    "        hold = hold.swapaxes(2,3)\n",
    "        hold = hold.reshape((x.shape[0],x.shape[1]/self.stride,x.shape[2]/self.stride,self.stride**2,x.shape[3]))\n",
    "        self.value = np.amax(hold,axis=3)\n",
    "        self.index = np.argmax(hold,axis=3)\n",
    "        \n",
    "\n",
    "    ####################### Please implement this function#######################             \n",
    "    def backward(self):\n",
    "        x = self.x.value\n",
    "        s=self.stride\n",
    "        hold = np.zeros((x.shape[0],x.shape[1]/self.stride,x.shape[2]/self.stride,self.stride**2,x.shape[3]))\n",
    "        hold[self.index] = 1\n",
    "        hold = hold.reshape((x.shape[0],x.shape[1]/self.stride,x.shape[2]/self.stride,self.stride,self.stride,x.shape[3]))\n",
    "        hold = hold.swapaxes(2,3)\n",
    "        hold = hold.reshape(x.shape)\n",
    "        if len(self.x.grad.shape) < 3:\n",
    "            self.x.grad = np.ndarray((x.shape))\n",
    "        for i in range(self.grad.shape[1]):\n",
    "            for j in range(self.grad.shape[2]):\n",
    "                for b in range(self.x.grad.shape[0]):\n",
    "                    for c in range(self.x.grad.shape[3]):\n",
    "                        self.x.grad[b,i:i+s,j:j+s,c] += np.multiply(self.grad[b,i,j,c],hold[b,i:i+s,j:j+s,c])\n",
    "\n",
    "                \n",
    "                            \n",
    "########################################### AvePool layer#############################################\n",
    "############################### Please implement the forward abd backward method in this class ##############                             \n",
    "class AvePool:\n",
    "    def __init__(self,x,ksz=2,stride=None):\n",
    "        edf.components.append(self)\n",
    "        self.x = x\n",
    "        self.ksz=ksz\n",
    "        if stride is None:\n",
    "            self.stride=ksz\n",
    "        else:\n",
    "            self.stride=stride\n",
    "        self.grad = None if x.grad is None else edf.DT(0)\n",
    "        \n",
    "    ####################### Please implement this function#######################   \n",
    "    def forward(self):\n",
    "        x = self.x.value\n",
    "        hold = x.reshape((x.shape[0],x.shape[1]/self.stride,self.stride,x.shape[2]/self.stride,self.stride,x.shape[3]))\n",
    "        hold = hold.swapaxes(2,3)\n",
    "        hold = hold.reshape((x.shape[0],x.shape[1]/self.stride,x.shape[2]/self.stride,self.stride**2,x.shape[3]))\n",
    "        self.value = np.mean(hold,axis=3)\n",
    "        self.index = np.argmax(hold,axis=3)\n",
    "        \n",
    "\n",
    "    ####################### Please implement this function#######################    \n",
    "    def backward(self):\n",
    "        self.x.grad += self.grad/(self.stride**2.0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'edf' from 'edf.pyc'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(edf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random test loss = 2.3077, accuracy = 0.1007\n",
      "Epoch 0: train loss = 2.3026 [1306.090 secs]\n",
      "test accuracy = 0.1001\n",
      "Epoch 1: train loss = 2.3026 [1276.446 secs]\n",
      "test accuracy = 0.1000\n",
      "Epoch 2: train loss = 2.3026 [1336.943 secs]\n",
      "test accuracy = 0.1000\n",
      "Epoch 3: train loss = 2.3026 [1533.500 secs]\n",
      "test accuracy = 0.1000\n",
      "Epoch 4: train loss = 2.3026 [1403.163 secs]\n",
      "test accuracy = 0.1000"
     ]
    }
   ],
   "source": [
    "# for repeatability\n",
    "np.random.seed(0)\n",
    "\n",
    "# Inputs\n",
    "inp = edf.Value()\n",
    "lab = edf.Value()\n",
    "\n",
    "\n",
    "prev_channel = 3 # RGB channel \n",
    "########################## Simple Convolution Nerual Network Model for Cifar 10 ##################################\n",
    "##################################################################################################################\n",
    "# please implement your main cnn model here, as described by the homework, you can mimic the previous code\n",
    "f1 = edf.Param(edf.xavier((3,3,3,32)))\n",
    "f2 = edf.Param(edf.xavier((3,3,32,64)))\n",
    "f3 = edf.Param(edf.xavier((1,1,64,10)))\n",
    "b1 = edf.Param(np.zeros((32)))\n",
    "b2 = edf.Param(np.zeros((64)))\n",
    "b3 = edf.Param(np.zeros((10)))\n",
    "\n",
    "hidden = edf.RELU(edf.Add(Conv(inp,f1,1,1),b1))\n",
    "MP = MaxPool(hidden,stride=4)\n",
    "hidden2 = edf.RELU(edf.Add(Conv(MP,f2,1,0),b2))\n",
    "hidden3 = AvePool(hidden2,stride=6)\n",
    "hidden4 = edf.RELU(edf.Add(Conv(hidden3,f3),b3))\n",
    "pred = edf.Reshape(hidden4,(100,10))\n",
    "\n",
    "\n",
    "\n",
    "# the standard classification layer, which you don't need to modify\n",
    "pred = edf.SoftMax(pred)\n",
    "loss = edf.Mean(edf.LogLoss(edf.Aref(pred,lab)))\n",
    "acc = edf.Accuracy(pred,lab)\n",
    "\n",
    "\n",
    "################################################################################################################## \n",
    "# evaluation bucket\n",
    "bucket = 100\n",
    "def eval_train():    \n",
    "    \n",
    "    # we only choose 1/5 of the train images for evaluation since evaluation the whole images is time consuming\n",
    "    eval_imgs = t_imgs[::5]\n",
    "    eval_labels = t_labels[::5]\n",
    "    avg_acc = 0\n",
    "    avg_loss = 0\n",
    "    \n",
    "    for seq in range(bucket):\n",
    "        inp.set(eval_imgs[seq::bucket])\n",
    "        lab.set(eval_labels[seq::bucket])\n",
    "        edf.Forward()\n",
    "        avg_acc += acc.value\n",
    "        avg_loss += loss.value\n",
    "    \n",
    "    return avg_acc/bucket, avg_loss/bucket\n",
    "        \n",
    "def eval_test():\n",
    "    \n",
    "    avg_acc = 0\n",
    "    avg_loss = 0\n",
    "    for seq in range(bucket):\n",
    "        inp.set(v_imgs[seq::bucket])\n",
    "        lab.set(v_labels[seq::bucket])\n",
    "        edf.Forward()\n",
    "        avg_acc += acc.value\n",
    "        avg_loss += loss.value\n",
    "    \n",
    "    return avg_acc/bucket, avg_loss/bucket\n",
    "\n",
    "# initial accuracy \n",
    "random_acc, random_loss = eval_test()\n",
    "print(\"Random test loss = %.4f, accuracy = %.4f\" % (random_loss, random_acc))\n",
    "\n",
    "\n",
    "################################################# train loop ######################################################\n",
    "ep = 0\n",
    "epoch = 10\n",
    "batch = 100\n",
    "train_loss = []; train_acc = []; test_loss =[]; test_acc = []\n",
    "stime = time()\n",
    "batches = range(0, len(t_labels), batch)\n",
    "\n",
    "while ep < epoch:\n",
    "\n",
    "    # randon shuffle the train data in each epoch\n",
    "    perm = np.random.permutation(len(t_labels))\n",
    "\n",
    "    for k in batches:\n",
    "        inp.set(t_imgs[perm[k:k+batch]])\n",
    "        lab.set(t_labels[perm[k:k+batch]])\n",
    "        edf.Forward()\n",
    "        edf.Backward(loss)\n",
    "        edf.Adam()\n",
    "\n",
    "        \n",
    "    # evaluate on trainset\n",
    "    t_acc, t_loss = eval_train()\n",
    "    print(\"Epoch %d: train loss = %.4f [%.3f secs]\" % (ep, t_loss,time()-stime))\n",
    "    train_loss.append(t_loss)\n",
    "    train_acc.append(t_acc)\n",
    "\n",
    "    # evaluate on testset\n",
    "    v_acc, v_loss = eval_test()\n",
    "    print(\"test accuracy = %.4f\" % v_acc)\n",
    "    test_loss.append(v_loss)\n",
    "    test_acc.append(v_acc)\n",
    "    stime = time()\n",
    "    ep += 1      \n",
    "\n",
    "\n",
    "# plot\n",
    "plt.figure(1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(len(test_loss)), test_loss, color='red')\n",
    "plt.plot(np.arange(len(train_loss)), train_loss, color='blue')\n",
    "plt.legend(['test loss', 'train loss'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(np.arange(len(test_acc)), test_acc, color='red')\n",
    "plt.plot(np.arange(len(train_acc)), train_acc, color='blue')\n",
    "plt.legend(['test acc', 'train acc'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly something wrong in the backprop section of the Conv class, but bug fixing has become increasingly difficult as the code takes extremely long to initialize and run. The backprop method in MaxPool could be done more efficiently, as the loops are slow, but I don't have the coding knowledge to make it any better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
