{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import edf\n",
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "train_data, trcnt = utils.load_data_onechar('data/ptb.train.txt')\n",
    "valid_data, vacnt = utils.load_data_onechar('data/ptb.valid.txt')\n",
    "test_data, tecnt = utils.load_data_onechar('data/ptb.test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: Perplexity: 3.39697 Avg loss = 148.88244\n",
      "Initial generated sentence \n",
      "the agreements bring the an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an \n",
      "Epoch 0: Perplexity: 3.05153 Avg loss = 135.63383 [21.497 mins]\n",
      "Epoch 0: generated sentence \n",
      "the agreements bring and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk>\n",
      "Epoch 1: Perplexity: 3.11051 Avg loss = 138.27753 [21.348 mins]\n",
      "Epoch 1: generated sentence \n",
      "the agreements bringing to the company said it will be some of the company said it will be some of the company said it will be some of the company said it will be some of the company said it will be some of the company said it will be some of the company said it will be some of the company said it will be some of the company said it will be some of the company said it will be some of the company s\n",
      "Epoch 2: Perplexity: 3.01121 Avg loss = 134.27425 [21.424 mins]\n",
      "Epoch 2: generated sentence \n",
      "the agreements bring the company 's <unk> and the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the\n",
      "Epoch 3: Perplexity: 3.06409 Avg loss = 136.51405 [21.488 mins]\n",
      "Epoch 3: generated sentence \n",
      "the agreements bringing the company 's securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the securities and the \n",
      "Epoch 4: Perplexity: 2.99556 Avg loss = 133.36066 [21.303 mins]\n",
      "Epoch 4: generated sentence \n",
      "the agreements bring the company 's <unk> <unk> and the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> \n",
      "Epoch 5: Perplexity: 2.97380 Avg loss = 132.66452 [21.592 mins]\n",
      "Epoch 5: generated sentence \n",
      "the agreements brings and the company 's company said it will be a company said the company said it will be a company said the company said it will be a company said the company said it will be a company said the company said it will be a company said the company said it will be a company said the company said it will be a company said the company said it will be a company said the company said it\n",
      "Epoch 6: Perplexity: 2.97874 Avg loss = 132.70943 [21.578 mins]\n",
      "Epoch 6: generated sentence \n",
      "the agreements bringing and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and the company 's <unk> <unk> and \n",
      "Epoch 7: Perplexity: 2.95263 Avg loss = 131.72646 [21.604 mins]\n",
      "Epoch 7: generated sentence \n",
      "the agreements bringing a series of the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's contract with the company 's c\n",
      "Epoch 8: Perplexity: 2.93634 Avg loss = 131.07029 [21.441 mins]\n",
      "Epoch 8: generated sentence \n",
      "the agreements brings and the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> \n",
      "Epoch 9: Perplexity: 2.93511 Avg loss = 130.85421 [21.489 mins]\n",
      "Epoch 9: generated sentence \n",
      "the agreements bringing the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market in the stock market\n",
      "Epoch 10: Perplexity: 2.93862 Avg loss = 131.16405 [21.457 mins]\n",
      "Epoch 10: generated sentence \n",
      "the agreements bringing the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <unk> and the <unk> <\n",
      "Epoch 11: Perplexity: 2.92377 Avg loss = 130.61539 [21.284 mins]\n",
      "Epoch 11: generated sentence \n",
      "the agreements bring the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the c\n",
      "Epoch 12: Perplexity: 2.91736 Avg loss = 130.22982 [21.458 mins]\n",
      "Epoch 12: generated sentence \n",
      "the agreements bringing a <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the company 's <unk> of the c\n",
      "Epoch 13: Perplexity: 2.90947 Avg loss = 129.90182 [21.385 mins]\n",
      "Epoch 13: generated sentence \n",
      "the agreements bringing a <unk> of the company 's stock market in the same time the company 's <unk> <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and\n",
      "Epoch 14: Perplexity: 2.94667 Avg loss = 131.59765 [21.282 mins]\n",
      "Epoch 14: generated sentence \n",
      "the agreements bringing the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the contract to the cont\n",
      "Epoch 15: Perplexity: 2.90770 Avg loss = 129.97944 [21.071 mins]\n",
      "Epoch 15: generated sentence \n",
      "the agreements bring and the company 's <unk> and the second part of the company 's <unk> and the company 's <unk> and the second part of the company 's <unk> and the company 's <unk> and the second part of the company 's <unk> and the company 's <unk> and the second part of the company 's <unk> and the company 's <unk> and the second part of the company 's <unk> and the company 's <unk> and the s\n",
      "Epoch 16: Perplexity: 2.88705 Avg loss = 129.09251 [21.092 mins]\n",
      "Epoch 16: generated sentence \n",
      "the agreements brings and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and\n",
      "Epoch 17: Perplexity: 2.88885 Avg loss = 129.08129 [20.963 mins]\n",
      "Epoch 17: generated sentence \n",
      "the agreements bring and the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> o\n",
      "Epoch 18: Perplexity: 2.88363 Avg loss = 128.96451 [20.802 mins]\n",
      "Epoch 18: generated sentence \n",
      "the agreements bring and steel 's <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> \n",
      "Epoch 19: Perplexity: 2.87384 Avg loss = 128.42127 [20.872 mins]\n",
      "Epoch 19: generated sentence \n",
      "the agreements brings and the company 's <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and\n",
      "Epoch 20: Perplexity: 2.88549 Avg loss = 128.90880 [20.831 mins]\n",
      "Epoch 20: generated sentence \n",
      "the agreements bring and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk>\n",
      "Epoch 21: Perplexity: 2.87735 Avg loss = 128.71284 [20.880 mins]\n",
      "Epoch 21: generated sentence \n",
      "the agreements bring and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk>\n",
      "Epoch 22: Perplexity: 2.85866 Avg loss = 127.75361 [20.822 mins]\n",
      "Epoch 22: generated sentence \n",
      "the agreements bringing and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> a\n",
      "Epoch 23: Perplexity: 2.86206 Avg loss = 127.96390 [21.564 mins]\n",
      "Epoch 23: generated sentence \n",
      "the agreements bringing the company 's <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <unk> and <\n",
      "Epoch 24: Perplexity: 2.84983 Avg loss = 127.48649 [20.959 mins]\n",
      "Epoch 24: generated sentence \n",
      "the agreements bringing a second quarter and the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company said the company sai\n",
      "Epoch 25: Perplexity: 2.84951 Avg loss = 127.41498 [20.899 mins]\n",
      "Epoch 25: generated sentence \n",
      "the agreements bringing the company 's state and <unk> and <unk> and <unk> the company 's <unk> and <unk> and <unk> the company 's <unk> and <unk> and <unk> the company 's <unk> and <unk> and <unk> the company 's <unk> and <unk> and <unk> the company 's <unk> and <unk> and <unk> the company 's <unk> and <unk> and <unk> the company 's <unk> and <unk> and <unk> the company 's <unk> and <unk> and <un\n",
      "Epoch 26: Perplexity: 2.84851 Avg loss = 127.41004 [20.995 mins]\n",
      "Epoch 26: generated sentence \n",
      "the agreements bring a <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the \n",
      "Epoch 27: Perplexity: 2.85040 Avg loss = 127.42571 [21.054 mins]\n",
      "Epoch 27: generated sentence \n",
      "the agreements bring and the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> of the <unk> o\n",
      "Epoch 28: Perplexity: 2.83698 Avg loss = 126.91877 [20.991 mins]\n",
      "Epoch 28: generated sentence \n",
      "the agreements bringing and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> and the company 's <unk> a\n",
      "Epoch 29: Perplexity: 2.84121 Avg loss = 126.99751 [21.227 mins]\n",
      "Epoch 29: generated sentence \n",
      "the agreements bringing the company 's computer companies are still a <unk> of the company 's computer companies are still a <unk> of the company 's computer companies are still a <unk> of the company 's computer companies are still a <unk> of the company 's computer companies are still a <unk> of the company 's computer companies are still a <unk> of the company 's computer companies are still a \n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 200\n",
    "n_vocab = utils.n_vocab\n",
    "batch = 50\n",
    "parameters = []\n",
    "model = 'model_LSTM.pkl'\n",
    "eta = 0.5\n",
    "decay = 0.9\n",
    "\n",
    "inp = edf.Value()\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "edf.params = []\n",
    "# LSTM parameters\n",
    "# input embedding\n",
    "C2V = edf.Param(edf.xavier((n_vocab, hidden_dim)))\n",
    "# forget gate\n",
    "Wf = edf.Param(edf.xavier((2*hidden_dim, hidden_dim)))\n",
    "bf = edf.Param(np.zeros((hidden_dim)))\n",
    "# input gate\n",
    "Wi = edf.Param(edf.xavier((2*hidden_dim, hidden_dim)))\n",
    "bi = edf.Param(np.zeros((hidden_dim)))\n",
    "# carry cell\n",
    "Wc = edf.Param(edf.xavier((2*hidden_dim, hidden_dim)))\n",
    "bc = edf.Param(np.zeros((hidden_dim)))\n",
    "# output cell\n",
    "Wo = edf.Param(edf.xavier((2*hidden_dim, hidden_dim)))\n",
    "bo = edf.Param(np.zeros((hidden_dim)))\n",
    "# output embedding\n",
    "V = edf.Param(edf.xavier((hidden_dim, n_vocab)))\n",
    "# for sake of saving\n",
    "parameters.extend([C2V, Wf, bf, Wi, bi, Wc, bc, Wo, bo, V])\n",
    "\n",
    "\n",
    "# load the trained model if exist\n",
    "if os.path.exists(model):\n",
    "    with open(model, 'rb') as f:\n",
    "        p_value = pickle.load(f)\n",
    "        idx = 0\n",
    "        for p in p_value:\n",
    "            parameters[idx].value = p\n",
    "            idx += 1\n",
    "                    \n",
    "\n",
    "# Please finish your LSTM cell in this function. it will build the model given the input inp, it should\n",
    "# return loss and prob score\n",
    "\n",
    "def BuildModel():\n",
    " \n",
    "    edf.components = []\n",
    "\n",
    "    batch = inp.value.shape[0]\n",
    "    score = []\n",
    "    \n",
    "    cInit = edf.Value(edf.xavier((batch,hidden_dim)))\n",
    "    hInit = edf.Value(edf.xavier((batch,hidden_dim)))\n",
    "    \n",
    "    data = edf.Value(inp.value[:,0])\n",
    "    mask = np.array([x != 0 for x in inp.value[:,0]]).astype(int)\n",
    "    xt = edf.Embed(data,C2V)\n",
    "    h,c = LSTMCell(xt, hInit, cInit)\n",
    "    pred = edf.SoftMax(edf.VDot(h,V))\n",
    "    score.append(pred)\n",
    "    ll = edf.LogLoss(edf.Aref(pred,edf.Value(inp.value[:,1])))\n",
    "    loss = edf.MeanwithMask(ll,edf.Value(mask))\n",
    "    \n",
    "    for i in range(1,inp.value.shape[1]-1):\n",
    "        data = edf.Value(inp.value[:,i])\n",
    "        mask = np.array([x != 0 for x in inp.value[:,i]]).astype(int)\n",
    "        xt = edf.Embed(data,C2V)\n",
    "        h,c = LSTMCell(xt, h, c)\n",
    "        pred = edf.SoftMax(edf.VDot(h,V))\n",
    "        score.append(pred)\n",
    "        ll = edf.LogLoss(edf.Aref(pred,edf.Value(inp.value[:,i+1])))\n",
    "        loss = edf.Add(edf.MeanwithMask(ll,edf.Value(mask)),loss)\n",
    "    \n",
    "    \n",
    "    return loss, score\n",
    "    \n",
    "    \n",
    "# calculate the perplexity         \n",
    "def CalPerp(score):\n",
    "    \n",
    "    prob = [p.value for p in score]\n",
    "    prob = np.transpose(np.stack(prob, axis = 0),(1,0,2))\n",
    "    B = prob.shape[0]\n",
    "    T = prob.shape[1]\n",
    "    V = prob.shape[2]\n",
    "    \n",
    "    masks = np.zeros((B, T), dtype=np.int32)\n",
    "    masks[inp.value[:,1:] != 0] = 1\n",
    "    \n",
    "    prob = prob.reshape(-1)\n",
    "    idx = np.int32(inp.value[:,1:].reshape(-1))\n",
    "    outer_dim = len(idx)\n",
    "    inner_dim = len(prob)/outer_dim\n",
    "    pick = np.int32(np.array(range(outer_dim))*inner_dim + idx)\n",
    "    prob = prob[pick].reshape(B, T)\n",
    "        \n",
    "    return -np.sum(np.log(prob[np.nonzero(prob*masks)]))\n",
    "\n",
    "\n",
    "def LSTMCell(xt, h, c):\n",
    "    hx = edf.ConCat(xt,h)\n",
    "    f = edf.Sigmoid(edf.Add(edf.VDot(hx,Wf),bf))\n",
    "    i = edf.Sigmoid(edf.Add(edf.VDot(hx,Wi),bi))\n",
    "    tempc = edf.Tanh(edf.Add(edf.VDot(hx,Wc),bc))\n",
    "    c_next = edf.Add(edf.Mul(i,tempc),edf.Mul(f,c))\n",
    "    o = edf.Sigmoid(edf.Add(edf.VDot(hx,Wo),bo))\n",
    "    h_next = edf.Mul(o,edf.Tanh(c_next))\n",
    "    \n",
    "    return h_next, c_next\n",
    "\n",
    "\n",
    "# predict the sequence\n",
    "def Predict(max_step, prefix):\n",
    "   \n",
    "    edf.components = []\n",
    "\n",
    "    T = max_step       \n",
    "    h = edf.Value(np.zeros((1, hidden_dim))) \n",
    "    c = edf.Value(np.zeros((1, hidden_dim))) \n",
    "    \n",
    "    prediction = []\n",
    "\n",
    "    for t in range(T):\n",
    "   \n",
    "        if t < len(prefix):\n",
    "            pred = edf.Value(prefix[t])\n",
    "            prediction.append(pred)              \n",
    "        else:\n",
    "            prediction.append(pred)\n",
    "\n",
    "        wordvec = edf.Embed(pred, C2V)\n",
    "        xt = edf.Reshape(wordvec, [-1, hidden_dim])\n",
    "        h_next,c_next = LSTMCell(xt, h, c)\n",
    "        p = edf.SoftMax(edf.VDot(h_next, V))\n",
    "        pred = edf.ArgMax(p)\n",
    "        h = h_next\n",
    "        c = c_next   \n",
    "            \n",
    "    edf.Forward()\n",
    "    \n",
    "    idx = [pred.value for pred in prediction]\n",
    "    stop_idx = utils.to_index('}')\n",
    "    \n",
    "    if stop_idx in idx:\n",
    "        return idx[0:idx.index(stop_idx)+1]\n",
    "    else:\n",
    "        return idx\n",
    "\n",
    "def Eval(data, cnt):\n",
    "    \n",
    "    perp = 0.\n",
    "    avg_loss = 0.\n",
    "    test_batches = range(0, len(data), batch)\n",
    "    test_minbatches = [data[idx:idx+batch] for idx in test_batches]\n",
    "    \n",
    "    for minbatch in test_minbatches:\n",
    "        \n",
    "        x_padded = utils.make_mask(minbatch)\n",
    "        inp.set(x_padded)\n",
    "        loss, score = BuildModel()\n",
    "        edf.Forward()\n",
    "        avg_loss += loss.value\n",
    "        perp += CalPerp(score)\n",
    "           \n",
    "    perp = np.exp(perp/cnt)\n",
    "    avg_loss /= len(test_batches)\n",
    "    return perp, avg_loss\n",
    "\n",
    "\n",
    "############################################### training loop #####################################################\n",
    "\n",
    "batches = range(0, len(train_data), batch)\n",
    "minbatches = [train_data[idx:idx+batch] for idx in batches]\n",
    "\n",
    "epoch = 30\n",
    "\n",
    "# initial Perplexity and loss\n",
    "perp, loss = Eval(valid_data, vacnt)\n",
    "print(\"Initial: Perplexity: %0.5f Avg loss = %0.5f\" % (perp, loss))    \n",
    "best_loss = loss\n",
    "prefix = 'the agreements bring'  \n",
    "generation = Predict(400, utils.to_idxs(prefix))\n",
    "print(\"Initial generated sentence \")\n",
    "print (utils.to_string(generation))\n",
    "    \n",
    "    \n",
    "for ep in range(epoch):\n",
    "\n",
    "    perm = np.random.permutation(len(minbatches)).tolist() \n",
    "    stime=time()\n",
    "    \n",
    "    for k in range(len(minbatches)):\n",
    "        \n",
    "        minbatch = minbatches[perm[k]]\n",
    "        x_padded = utils.make_mask(minbatch)\n",
    "        inp.set(x_padded)\n",
    "        loss, score = BuildModel()\n",
    "        edf.Forward()\n",
    "        edf.Backward(loss)\n",
    "        edf.GradClip(10)\n",
    "        edf.SGD(eta)\n",
    "       \n",
    "    duration = (time() - stime)/60.\n",
    "    \n",
    "    perp, loss = Eval(valid_data, vacnt)\n",
    "    print(\"Epoch %d: Perplexity: %0.5f Avg loss = %0.5f [%.3f mins]\" % (ep, perp, loss, duration))\n",
    "    \n",
    "    # generate some text given the prefix and trained model\n",
    "    prefix = 'the agreements bring'  \n",
    "    generation = Predict(400, utils.to_idxs(prefix))\n",
    "    print(\"Epoch %d: generated sentence \" % ep)\n",
    "    print (utils.to_string(generation)) \n",
    "\n",
    "    if loss < best_loss:\n",
    "        \n",
    "        best_loss = loss\n",
    "        # save the model\n",
    "        f = open(model, 'wb')\n",
    "        p_value = []\n",
    "        for p in parameters:\n",
    "            p_value.append(p.value)\n",
    "        pickle.dump(p_value, f)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # load the last best model and decay the learning rate\n",
    "        eta *= decay\n",
    "        with open(model, 'rb') as f:\n",
    "            p_value = pickle.load(f)\n",
    "            idx = 0\n",
    "            for p in p_value:\n",
    "                parameters[idx].value = p\n",
    "                idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran out of time training the model, seems like it would converge after enough epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'edf' from 'edf.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(edf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "f = open(model, 'wb')\n",
    "p_value = []\n",
    "for p in parameters:\n",
    "    p_value.append(p.value)\n",
    "pickle.dump(p_value, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
